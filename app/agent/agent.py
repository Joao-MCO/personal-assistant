import datetime
import hashlib
import json
import operator
import logging
import streamlit as st
from typing import TypedDict, Annotated, Sequence, List, Union, Dict, Any
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from utils.files import get_emails
from utils.settings import WrappedSettings as Settings
from utils.tool_cache import ToolResultCache
from agent.llm_factory import LLMFactory
from prompts.templates import AGENT_SYSTEM_PROMPT
from tools.manager import agent_tools
from tools.google_tools import CheckCalendar, CreateEvent
from tools.gmail import CheckEmail, SendEmail
from services.google_auth import GoogleCredentialManager
from threading import Lock
import html

logger = logging.getLogger(__name__)


class AgentState(TypedDict):
    """Estado do agente com hist√≥rico de mensagens"""
    messages: Annotated[Sequence[BaseMessage], operator.add]


class AgentFactory:
    """
    Factory para criar e gerenciar agente IA com LangGraph.
    
    Caracter√≠sticas:
    - Suporte a m√∫ltiplos modelos LLM
    - Cache inteligente com TTL
    - Valida√ß√£o de credenciais
    - Error handling robusto
    - Rate limiting (delegado a main.py)
    """
    
    def __init__(self, llm: str = "gemini"):
        """
        Inicializa AgentFactory
        
        Args:
            llm: Modelo LLM a usar ('gemini', 'gpt', etc)
        
        Raises:
            ValueError: Se modelo inv√°lido
            RuntimeError: Se erro ao inicializar LLM
        """
        logger.info(f"Inicializando AgentFactory com modelo: {llm}")
        
        try:
            # 1. Inicializar LLM com valida√ß√£o
            self.llm = LLMFactory.create_llm(llm)
        except (ValueError, RuntimeError) as e:
            logger.error(f"Erro ao inicializar LLM: {e}")
            raise
        
        # 2. Ferramentas que precisam de credenciais do usu√°rio (Runtime)
        self.create_event_tool = CreateEvent()
        self.check_calendar_tool = CheckCalendar()
        self.check_email_tool = CheckEmail()
        self.send_email_tool = SendEmail()
        
        # 3. Ferramentas Globais + Ferramentas de Sess√£o
        global_tools = [
            t for t in agent_tools
            if t.name not in [
                "CriarEvento", "ConsultarAgenda",
                "ConsultarEmail", "EnviarEmail"
            ]
        ]
        
        self.tools = global_tools + [
            self.create_event_tool, 
            self.check_calendar_tool, 
            self.check_email_tool, 
            self.send_email_tool
        ]
        
        # Vincular ferramentas ao modelo
        try:
            self.llm_with_tools = self.llm.bind_tools(self.tools)
            logger.info(f"‚úÖ {len(self.tools)} ferramentas vinculadas ao LLM")
        except NotImplementedError:
            logger.warning(
                f"‚ö†Ô∏è Modelo '{llm}' n√£o suporta bind_tools nativamente. "
                f"Agente funcionar√° apenas como CHAT."
            )
            self.llm_with_tools = self.llm
        except Exception as e:
            logger.error(f"Erro ao vincular ferramentas: {e}", exc_info=True)
            self.llm_with_tools = self.llm
        
        # 4. Cache inteligente com TTL
        self.cache = ToolResultCache(default_ttl_minutes=10)
        self.cache_lock = Lock()
        
        # 5. Contexto Temporal e Din√¢mico
        self._initialize_system_prompt()
        
        # 6. Criar grafo do agente
        self.graph = self._create_graph()
        
        logger.info("‚úÖ AgentFactory inicializado com sucesso")

    def _initialize_system_prompt(self) -> None:
        """Inicializa prompt do sistema com contexto din√¢mico"""
        try:
            emails_str = get_emails(True)
        except Exception as e:
            logger.warning(f"N√£o foi poss√≠vel carregar emails: {e}")
            emails_str = ""
        
        agora = datetime.datetime.now()
        dias_pt = {
            "Monday": "Segunda-feira", "Tuesday": "Ter√ßa-feira",
            "Wednesday": "Quarta-feira", "Thursday": "Quinta-feira",
            "Friday": "Sexta-feira", "Saturday": "S√°bado", "Sunday": "Domingo"
        }
        
        formatted_system_prompt = AGENT_SYSTEM_PROMPT.format(
            dia_hoje_pt=dias_pt.get(agora.strftime("%A"), ""),
            data_hoje=agora.strftime("%d/%m/%Y"),
            hora_agora=agora.strftime("%H:%M"),
            emails_str=emails_str
        )
        
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", formatted_system_prompt),
            MessagesPlaceholder(variable_name="messages"),
        ])

    def _create_graph(self) -> Any:
        """Cria grafo de execu√ß√£o do agente"""
        workflow = StateGraph(AgentState)
        
        def call_model(state: AgentState):
            """Chama modelo LLM"""
            messages = state["messages"]
            chain = self.prompt | self.llm_with_tools
            response = chain.invoke({"messages": messages})
            return {"messages": [response]}
        
        def router_logic(state: AgentState) -> str:
            """Rota l√≥gica para ferramentas ou fim"""
            messages = state["messages"]
            last_message = messages[-1]
            
            if not hasattr(last_message, "tool_calls") or not last_message.tool_calls:
                return "end"
            
            return "continue"
        
        def after_tools_router(state: AgentState) -> str:
            """Rota l√≥gica ap√≥s execu√ß√£o de ferramentas"""
            messages = state["messages"]
            last_message = messages[-1]
            
            if isinstance(last_message, ToolMessage):
                # Algumas ferramentas s√£o finais
                if last_message.name in ["AjudaProgramacao", "DuvidasRPG"]:
                    return "end"
                return "agent"
            return "agent"
        
        workflow.add_node("agent", call_model)
        workflow.add_node("tools", ToolNode(self.tools))
        
        workflow.set_entry_point("agent")
        
        workflow.add_conditional_edges("agent", router_logic, {
            "continue": "tools", 
            "end": END
        })
        
        workflow.add_conditional_edges("tools", after_tools_router, {
            "agent": "agent", 
            "end": END
        })
        
        logger.info("‚úÖ Grafo do agente compilado")
        return workflow.compile()

    def _reconstruct_history(self, session_messages: List[Dict[str, Any]]) -> List[BaseMessage]:
        """
        Reconstr√≥i hist√≥rico de mensagens para LangChain
        
        Args:
            session_messages: Hist√≥rico de mensagens da sess√£o Streamlit
        
        Returns:
            Lista de mensagens BaseMessage
        """
        history = []
        
        for msg in session_messages:
            if not isinstance(msg, dict):
                continue
            
            role = msg.get("role", "").lower()
            content = str(msg.get("content", "")).strip()
            
            if not content:
                continue
            
            try:
                if role == "user":
                    history.append(HumanMessage(content=content))
                elif role == "assistant":
                    history.append(AIMessage(content=content))
            except Exception as e:
                logger.warning(f"Erro ao reconstruir mensagem: {e}")
                continue
        
        return history

    def _get_cached_result(self, tool_name: str, **kwargs) -> Any:
        """Obt√©m resultado em cache se dispon√≠vel"""
        with self.cache_lock:
            return self.cache.get(tool_name, **kwargs)

    def _cache_result(self, tool_name: str, result: Any, ttl_minutes: int = None, **kwargs):
        """Armazena resultado em cache"""
        with self.cache_lock:
            self.cache.set(tool_name, result, ttl_minutes=ttl_minutes, **kwargs)

    def _add_user_context_safely(
        self,
        current_content: List[Dict[str, Any]],
        user_infos: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        Adiciona contexto do usu√°rio de forma segura (anti-injection)
        
        Args:
            current_content: Conte√∫do atual da mensagem
            user_infos: Informa√ß√µes do usu√°rio
        
        Returns:
            Conte√∫do com contexto adicionado
        """
        try:
            user_name = str(user_infos.get('user', 'Unknown'))[:100]
            user_email = str(user_infos.get('email', ''))[:200]
            
            # Validar email b√°sico
            if '@' not in user_email:
                user_email = ''
            
            # Usar HTML escape para prevenir injection
            user_name_safe = html.escape(user_name)
            user_email_safe = html.escape(user_email)
            
            # Adicionar contexto de forma estruturada
            current_content.append({
                "type": "text",
                "text": f"[CONTEXTO USU√ÅRIO: Nome={user_name_safe}, Email={user_email_safe}]"
            })
            
            return current_content
        
        except Exception as e:
            logger.warning(f"Erro ao adicionar contexto do usu√°rio: {e}")
            return current_content

    def invoke(
        self,
        input_text: str,
        session_messages: List[Dict[str, Any]],
        uploaded_files: List[Dict[str, Any]] = None,
        user_credentials: Any = None,
        user_infos: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """
        Invoca o agente com entrada do usu√°rio
        
        Args:
            input_text: Texto de entrada do usu√°rio
            session_messages: Hist√≥rico de mensagens
            uploaded_files: Arquivos anexados
            user_credentials: Credenciais OAuth do Google
            user_infos: Informa√ß√µes do usu√°rio
        
        Returns:
            Dict com sa√≠da do agente
        
        Raises:
            RuntimeError: Se erro na execu√ß√£o
        """
        try:
            # 1. Configurar credenciais nas ferramentas
            if user_credentials:
                # Validar e refresh credenciais se necess√°rio
                if not GoogleCredentialManager.ensure_valid_credentials(user_credentials):
                    logger.warning("Credenciais inv√°lidas ou expiradas")
                    return {
                        "output": [{
                            "role": "assistant",
                            "content": "‚ö†Ô∏è Suas credenciais expiraram. Fa√ßa login novamente."
                        }]
                    }
                
                for tool in [
                    self.create_event_tool,
                    self.check_calendar_tool,
                    self.check_email_tool,
                    self.send_email_tool
                ]:
                    tool.set_credentials(user_credentials)
                
                logger.debug("‚úÖ Credenciais configuradas nas ferramentas")
            
            # 2. Reconstruir hist√≥rico
            lc_messages = self._reconstruct_history(session_messages)
            
            # 3. Preparar conte√∫do da mensagem atual
            current_content: List[Dict[str, Any]] = []
            
            if input_text:
                current_content.append({
                    "type": "text",
                    "text": input_text
                })
            
            if uploaded_files:
                file_names = ", ".join(
                    [f.get("name", "arquivo") for f in uploaded_files]
                ) if uploaded_files else "arquivos"
                
                current_content.append({
                    "type": "text",
                    "text": f"\n[ARQUIVO]: Anexados: {file_names}"
                })
                
                # Processar imagens
                for file in uploaded_files:
                    if file.get('mime', '').startswith('image/'):
                        try:
                            import base64
                            encoded = base64.b64encode(file['data']).decode('utf-8')
                            current_content.append({
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:{file['mime']};base64,{encoded}"
                                }
                            })
                        except Exception as e:
                            logger.warning(f"Erro ao processar imagem: {e}")
            
            # 4. Adicionar contexto do usu√°rio (seguro)
            if user_infos and 'email' in user_infos and 'user' in user_infos:
                current_content = self._add_user_context_safely(
                    current_content,
                    user_infos
                )
            
            # 5. Adicionar mensagem ao hist√≥rico
            lc_messages.append(HumanMessage(content=current_content))
            
            # 6. Invocar agente
            logger.info("Invocando LangGraph...")
            result = self.graph.invoke({"messages": lc_messages})
            
            # 7. Processar resposta
            last_message = result["messages"][-1]
            content = last_message.content
            
            # Tratar conte√∫do em lista (alguns modelos retornam assim)
            if isinstance(content, list):
                text_parts = []
                for part in content:
                    if isinstance(part, dict) and "text" in part:
                        text_parts.append(part["text"])
                    elif hasattr(part, "text"):
                        text_parts.append(part.text)
                    elif isinstance(part, str):
                        text_parts.append(part)
                content = "\n".join(text_parts)
            
            # Validar conte√∫do
            if not content:
                if hasattr(last_message, "tool_calls") and last_message.tool_calls:
                    logger.debug("Resposta vazia mas com tool_calls")
                    content = "ü§î Processando ferramentas..."
                else:
                    logger.debug("Resposta vazia da LLM")
                    content = "‚úÖ Feito."
            
            logger.info("‚úÖ Agent.invoke finalizado com sucesso")
            return {
                "output": [{
                    "role": "assistant",
                    "content": str(content)
                }]
            }
        
        except Exception as e:
            logger.error(f"Erro na execu√ß√£o do agente: {str(e)}", exc_info=True)
            return {
                "output": [{
                    "role": "assistant",
                    "content": f"‚ùå Erro: {str(e)[:200]}"
                }]
            }